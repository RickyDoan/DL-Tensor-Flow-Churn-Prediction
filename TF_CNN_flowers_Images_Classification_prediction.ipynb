{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1_tTIpJPhJhb-JX8S_rINyKJ1ebrXxqVC",
      "authorship_tag": "ABX9TyOcZCCY4z2N2KzjfzTFyS1c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickyDoan/DL-Tensor-Flow-Prediction/blob/main/TF_CNN_flowers_Images_Classification_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdB7mWiPOSag"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "import pathlib\n",
        "import cv2\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "GiTJFz2p6POH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flower_photo/\n",
        "#   daisy/\n",
        "#   dandelion/\n",
        "#   roses/\n",
        "#   sunflowers/\n",
        "#   tulips/"
      ],
      "metadata": {
        "id": "T4cFR3SiShuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "# dataset_url =\n",
        "# data_dir = tf.keras.utils.get_file('flower_photos', cache_dir='/content/drive/MyDrive/A Learning Tensor Flow/CNN-Image Classification', origin=dataset_url, untar=True)"
      ],
      "metadata": {
        "id": "BPucWlnySr1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_dir"
      ],
      "metadata": {
        "id": "S_CsJKU1TH1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/A Learning Tensor Flow/CNN-Image Classification/datasets/flower_photos\""
      ],
      "metadata": {
        "id": "XZMhF94-3VL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(data_dir)\n",
        "data_dir"
      ],
      "metadata": {
        "id": "FiSUhIu4UQ7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "2otnVMTxTI1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "metadata": {
        "id": "KOJjQooDUZhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 5, figsize=(10, 10))\n",
        "axes = axes.flatten()\n",
        "for i in range(5):\n",
        "    image = PIL.Image.open(str(roses[i]))\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_xticks([])\n",
        "    axes[i].set_yticks([])\n",
        "    axes[i].grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yLDdB_dfU3SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tulips = list(data_dir.glob('tulips/*'))\n",
        "PIL.Image.open(str(tulips[0]))"
      ],
      "metadata": {
        "id": "KA_a29qiU6Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flowers_images_dict = {\n",
        "    'roses': list(data_dir.glob('roses/*')),\n",
        "    'daisy': list(data_dir.glob('daisy/*')),\n",
        "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
        "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
        "    'tulips': list(data_dir.glob('tulips/*')),\n",
        "}\n",
        "\n",
        "flowers_labels_dict = {\n",
        "    'roses': 0,\n",
        "    'daisy': 1,\n",
        "    'dandelion': 2,\n",
        "    'sunflowers': 3,\n",
        "    'tulips': 4,\n",
        "}"
      ],
      "metadata": {
        "id": "RNC7vRpVXTYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flowers_images_dict['roses'][:5]"
      ],
      "metadata": {
        "id": "boik0hvuXy5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(flowers_images_dict['roses'][0])"
      ],
      "metadata": {
        "id": "AlzpT_TXX2-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(str(flowers_images_dict['roses'][0]))\n",
        "img"
      ],
      "metadata": {
        "id": "hP-o-rT7YGB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "F29dopDKYyWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = np.array(X)\n",
        "# y = np.array(y)"
      ],
      "metadata": {
        "id": "5rGb0Vsjaybh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X.shape"
      ],
      "metadata": {
        "id": "wmhMqCh3a03p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "u46xsANDaRkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "agctSUGSaXEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = train_ds.class_names\n",
        "print(class_name)"
      ],
      "metadata": {
        "id": "LXK9zPZwbXv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "B3Oj6rWiB0C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training mode"
      ],
      "metadata": {
        "id": "4mTFUntya-ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_name)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
        "model.evaluate(val_ds)"
      ],
      "metadata": {
        "id": "0GYjYOYfbAi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jpIYXeVe7v7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8LkyVr_D3CLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augumentation = keras.Sequential([\n",
        "    keras.layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
        "    keras.layers.RandomRotation(0.1),\n",
        "    keras.layers.RandomZoom(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "IDEYl_sO8Rpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_name)\n",
        "model_aug = keras.Sequential([\n",
        "    data_augumentation,\n",
        "    keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model_aug.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    history = model_aug.fit(train_ds, validation_data=val_ds, epochs=30)\n",
        "model_aug.evaluate(val_ds)"
      ],
      "metadata": {
        "id": "O10YOukz8aeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b-XOnt2TIGvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ],
      "metadata": {
        "id": "SG0vIYHTKSGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create code to predict 10 random image from my folder.\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Assuming 'data_dir' and 'model_aug' are defined from the previous code.\n",
        "# If not, define them as shown in the previous code block.\n",
        "\n",
        "def predict_random_images(num_images=20):\n",
        "    \"\"\"Predicts the class of random images from the dataset and displays them.\"\"\"\n",
        "\n",
        "    random_image_paths = random.sample(list(data_dir.glob('*/*.jpg')), num_images)\n",
        "    fig, axes = plt.subplots(4,5, figsize=(20, 10))\n",
        "    axes = axes.flatten()\n",
        "    for idx, image_path in enumerate(random_image_paths):\n",
        "        img = cv2.imread(str(image_path))\n",
        "        img = cv2.resize(img, (img_height, img_width))  # Resize the image\n",
        "        img_array = tf.keras.utils.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "        predictions = model_aug.predict(img_array)\n",
        "        predicted_class = class_names[np.argmax(predictions[0])]\n",
        "\n",
        "        # Get the true label from the image path\n",
        "        true_label = os.path.basename(os.path.dirname(str(image_path)))\n",
        "\n",
        "        # plt.figure()\n",
        "        axes[idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        axes[idx].set_title(f\"Pred: {predicted_class}, Label : {true_label} \")\n",
        "        axes[idx].axis(\"off\")\n",
        "    plt.tight_layout\n",
        "    plt.show()\n",
        "\n",
        "predict_random_images()"
      ],
      "metadata": {
        "id": "3TNRrLFvJDPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predict = model_aug.predict(val_ds)\n",
        "predict = np.argmax(predict, axis=1)\n",
        "true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "print(classification_report(true, predict, target_names=class_name))"
      ],
      "metadata": {
        "id": "aebowIMpRmTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = []\n",
        "# y = []\n",
        "# for flowers_name, images in flowers_images_dict.items():\n",
        "#     for image in images:\n",
        "#         img = cv2.imread(str(image))\n",
        "#         resized_img = cv2.resize(img, (180, 180))\n",
        "#         X.append(resized_img)\n",
        "#         y.append(flowers_labels_dict[flowers_name])"
      ],
      "metadata": {
        "id": "WS0UGvlR93UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = np.array(X)\n",
        "# y = np.array(y)"
      ],
      "metadata": {
        "id": "kCkSmSjg953K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)"
      ],
      "metadata": {
        "id": "ykhLz9c097Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train/255\n",
        "# X_test = X_test/255"
      ],
      "metadata": {
        "id": "ezpm0cqr-Oax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_augument = Sequential([\n",
        "#     layers.RandomFlip(\"horizontal\", input_shape=(180, 180, 3)),\n",
        "#     layers.RandomRotation(0.1),\n",
        "#     layers.RandomZoom(0.1),\n",
        "# ])"
      ],
      "metadata": {
        "id": "kcSUV5q2APaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_classes = len(class_name)\n",
        "# model_augumentation = Sequential([\n",
        "#     data_augument,\n",
        "#     layers.Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "#     layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "#     layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "#     layers.Dropout(0.2),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(64, activation='relu'),\n",
        "#     layers.Dense(num_classes)\n",
        "# ])\n",
        "# model_augumentation.compile(optimizer='adam',\n",
        "#               loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# with tf.device('/device:GPU:0'):\n",
        "#     model_augumentation.fit(X_train, y_train, epochs=30)\n",
        "# model_augumentation.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "oyWphMIlCmDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0uJqY27-DN7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}